The setup uses two AIs because they each have different jobs:

AI-1 is the “talking AI.” Its only job is to chat with the user and always reply in a simple JSON format with two fields:

message → what it says to the user.

action → tells us if it should handle the request itself (none) or pass it to the second AI (pass_to_AI2).

AI-2 is the “expenses AI.” It doesn’t chat about general topics. It only updates or reads from the expenses system (add, change, delete, or show expenses).

This design is important because:

Clear separation of roles → AI-1 can be clever and conversational, while AI-2 stays safe and focused on money data.

Safety → Only AI-2 can touch the database. AI-1 cannot make mistakes with data.

Reliability → Since AI-1 must always give JSON, the system can easily read its answer and know exactly what to do next.

Flexibility → Later you can improve AI-1’s “conversation” without breaking the expense logic in AI-2.

## Feature Plan — AI-1/AI-2 Orchestration and Strict JSON Routing

### Context
We will introduce a small orchestration layer in `netlify/functions/chat.js` that enforces a strict JSON routing contract for AI-1 and delegates expense CRUD to AI-2 backed by a safe service/repo. This keeps our current stack and minimizes dependencies.

### Goals
- Enforce strict JSON replies from AI-1: `{ message: string, action: 'none'|'pass_to_AI2' }`.
- Route expense-related intents to AI-2 which performs CRUD via a scoped `ExpenseService`.
- Keep implementation dependency-light (native `fetch`), easy to swap model providers.
- Preserve our current Netlify function entry and error semantics.

### Files to update/create
- `netlify/functions/chat.js`
  - Replace current Gemini-first flow with orchestrator: call AI-1, validate strict JSON, conditionally call AI-2.
  - Keep method guard (POST only) and JSON parsing with helpful error responses.
  - Return shape: `{ handledBy: 'AI-1'|'AI-2', message: string, action: 'none'|'pass_to_AI2' }` on 200.
  - On errors, return `{ error, detail? }` with 4xx/5xx statuses as appropriate.
  - Include an in-memory repo (default) to avoid DB coupling, with a clear seam to replace with Supabase.
- (No UI changes required for this plan.)

### Orchestration Design
- Entry validates `POST` and parses `{ history, userContext }`.
- Call AI-1 with a system prompt instructing strict JSON only.
- Validate shape; retry once if invalid; fail with 500 if still invalid.
- If `action === 'pass_to_AI2'`, construct `ExpenseService` with `InMemoryExpenseRepo` (default) and call AI-2 with `userText`, `history`, and `userContext`.
- AI-2 applies minimal intent parsing for: create, delete, update, list.
- All writes check role-based permission (e.g., `finance-admin` or `super-admin`).
- Always scope by `tenantId` in service methods.

### ExpenseService
- Methods: `create`, `update`, `delete`, `list`, `getById`.
- Throws on cross-tenant access or missing rows.
- Default repo: `InMemoryExpenseRepo` with `id` sequence and basic CRUD, sorted list by `id desc`.
- Seam to swap in Supabase-backed repo later.

### API Contract
Request: `POST /.netlify/functions/chat`
- Body: `{ history: Array<{role:'user'|'assistant', content:string}>, userContext?: { userId:string, tenantId:string, roles:string[] } }`
- `history` must be a non-empty array; `userContext` defaults to unknown IDs if omitted.

Responses:
- 200 OK: `{ handledBy, message, action }`
- 400: `{ error: 'history (array) is required' | 'Invalid JSON body' }`
- 405: `{ error: 'Method Not Allowed' }`
- 500: `{ error: 'Server error', detail }`

### Acceptance Criteria
- AI-1 responses are validated; non-JSON or schema-mismatched responses are retried once, then fail with 500.
- Expense intents (add/create/log, delete #id, update #id, list) are handled by AI-2 with tenant scoping and permission checks for writes.
- Non-expense queries return AI-1’s message with `action:'none'` and `handledBy:'AI-1'`.
- No additional runtime dependencies required beyond `fetch`.
- Build succeeds and Netlify function deploys.

### Notes & Future Work
- Swap `fakeModelJSON` and `fakeGeminiExplain` with real providers (OpenAI/Gemini) without changing the orchestrator API.
- Replace `InMemoryExpenseRepo` with Supabase repo when ready; keep the same service interface.
- Consider extracting AI-2 intent parsing to a dedicated classifier or structured extraction if needed.