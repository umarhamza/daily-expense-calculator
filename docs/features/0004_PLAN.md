## 0003 - Voice-to-Text in Chat (Microphone Trigger)

### Context
Add front-end voice-to-text in the chat. The user can tap a microphone icon to dictate a prompt; the recognized text appears in the input, and they can send it. Use browser-native APIs where available, avoid backend/audio upload. Keep edits minimal and scoped to the chat UI and a new composable.

- “Add a voice to text functionality in the chat from the front end” and “add a microphone icon”
- Progressive enhancement: feature-detect speech recognition and gracefully degrade when unsupported
- No server changes; do not store audio

### Files To Change / Create
- New: `src/lib/useSpeechToText.js` — composable wrapper around Web Speech API (`SpeechRecognition`/`webkitSpeechRecognition`)
- New: `src/components/icons/IconMicrophone.vue` — simple microphone SVG icon (match existing icon pattern)
- Optional New: `src/components/icons/IconStop.vue` — stop/recording-state icon (if we want a distinct stop visual)
- Edit: `src/components/ChatModal.vue` — add microphone button in the input row; wire up listening state and transcription; minor UI state updates

---

### Implementation Details

1) Composable: `useSpeechToText.js`
   - Purpose: Provide a declarative API for voice capture and transcription via Web Speech API.
   - Exported state and actions:
     - `isSupported` (boolean): feature detection for `SpeechRecognition` or `webkitSpeechRecognition`.
     - `isListening` (boolean): whether recognition is active.
     - `transcript` (string): last final transcript result.
     - `errorMessage` (string): last error encountered; empty when none.
     - `start(options?)` and `stop()`: control recording; options include `{ language?: string, continuous?: boolean, interimResults?: boolean }`.
   - Algorithm (step-by-step):
     1. Detect `window.SpeechRecognition || window.webkitSpeechRecognition`. If absent, set `isSupported=false` and no-op methods.
     2. On `start()`:
        - Guard: if unsupported or already listening, return.
        - Instantiate recognition; configure: `lang = navigator.language` (fallback `'en-US'`), `continuous=false`, `interimResults=false`.
        - Bind handlers:
          - `onresult`: read `event.results`, accumulate final transcript (join alternatives), set `transcript`.
          - `onerror`: set `errorMessage` with `event.error` code; set `isListening=false`.
          - `onend`: set `isListening=false` (stop state) when the session ends.
        - Call `recognition.start()`; set `isListening=true`; clear `transcript` and `errorMessage`.
     3. On `stop()`:
        - Guard: if not listening, return.
        - Call `recognition.stop()`; state will flip to false in `onend`.
     4. Cleanup: expose a `dispose()` or internally manage recognition instance so it cannot leak across starts; stop on component unmount.
   - Errors: throw only on exceptional programmer misuse (e.g., start when unsupported). For runtime API errors, surface via `errorMessage` and let the UI decide (toast or inline message).

2) UI Integration: `ChatModal.vue`
   - Input row currently contains the text input and Send button.
   - Add a small square icon button (microphone) before the Send button:
     - States:
       - Idle: show microphone icon; enabled if `isSupported` and not `isSending`.
       - Listening: visually highlighted (primary background), optionally change to a stop icon; pressing toggles `stop()`.
       - Disabled: when `!isSupported` or `isSending`.
     - Accessibility: `aria-label="Start voice input"` / `aria-pressed` while listening; focusable; visible label for screen readers.
   - Interaction flow:
     1. On click (idle): call `start()`; set listening state.
     2. When `transcript` updates with a non-empty string:
        - Put the transcript into the existing `input` model, replacing any previous text.
        - Do not auto-send by default. The user can edit or press Enter/Send. Optionally consider a long-press in future to auto-send.
     3. On click (listening): call `stop()`.
     4. On error: show `showErrorToast(errorMessage)` and render a small inline error under the input (reuse existing `errorMessage` pattern or a local one for STT).
   - Disable conditions:
     - While `isSending` is true, disable mic interactions.
     - When `!isSupported`, either hide the mic button or render it disabled with a tooltip “Voice input not supported in this browser”. Prefer hide on small screens to reduce clutter.

3) Icons
   - `IconMicrophone.vue`: follow existing icon components in `src/components/icons` (simple `<svg>` wrapped in a component). No external library changes needed.
   - Optional `IconStop.vue`: a small square/stop icon to indicate the recording state; otherwise retain microphone with an active ring style.

4) Localization
   - Use `navigator.language` as default recognition language; allow an optional parameter in `start({ language })` for future customization.

5) Performance & Privacy
   - No audio is sent to our servers; transcription is handled by the browser engine.
   - Limit recording to a single short utterance (`continuous=false`), minimizing on-device processing time.

---

### Progressive Enhancement & Fallbacks
- Feature detection: if the Web Speech API is unavailable, the UI continues to work with text-only input. Hide or disable the mic button accordingly.
- If permission is denied or the microphone is blocked, show a toast with guidance to enable the microphone in browser settings.
- If recognition stops immediately with no result (e.g., silence), leave input unchanged and show a subtle toast: “Didn’t catch that—try again closer to the mic.”

---

### Testing & QA
- Environments: Chrome (desktop/mobile), Edge, and Safari/Firefox behavior (expect unsupported; verify graceful degradation). Android Chrome is primary target for mobile.
- Scenarios:
  - Start/stop listening; cancel mid-utterance; allow auto-stop on end.
  - Successful transcription populates input and can be sent.
  - Disabled while message is sending.
  - Error handling: permission denied, network, no-speech, audio-capture-error.
  - Accessibility: focus order, screen reader labels, ARIA pressed state reflects listening.
- Build: No dependency changes expected; `npm run build` should remain clean.

---

### Non-Goals (Now)
- Server-side transcription or audio upload.
- Streaming partial transcripts into the message list.
- Global settings UI for input language selection.

---

### Work Breakdown (Small, Parallelizable)
1) Create `src/lib/useSpeechToText.js` composable with `isSupported`, `isListening`, `transcript`, `errorMessage`, `start`, `stop`.
2) Add `src/components/icons/IconMicrophone.vue` (and optional `IconStop.vue`).
3) Update `src/components/ChatModal.vue` input row to include mic button, bind to composable, and handle result → input assignment and errors.
4) QA on Chrome desktop and Android; verify graceful fallback on unsupported browsers.

